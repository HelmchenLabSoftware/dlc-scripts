{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLC Postprocess Library\n",
    "\n",
    "Run after training has been performed, and at least 1 video has been analyzed\n",
    "\n",
    "**Plan:**\n",
    "1. Load config file, tracked video, and tracking results\n",
    "2. Speci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py36qt5/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from PyQt5.QtWidgets import QFileDialog\n",
    "\n",
    "import deeplabcut\n",
    "\n",
    "from lib.parse_dlc_csv import parse_dlc_csv\n",
    "from lib.constraints import likelihood_constrain, velocity_constrain, edge_constrain\n",
    "from lib.plots import plotPerrCDF, plotVelocityCDF, plotRelEdgeLenDistr\n",
    "from lib.stickman import stickman\n",
    "from lib.qt_wrapper import gui_fname, gui_fpath\n",
    "from lib.sampling import selectUniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter parameters for the analysis of DLC marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using original video /media/aleksejs/DataHDD/work/data/Pia/Tracking20181022_compressed/2018.10.22_18_01_56.avi\n",
      "Using tracking file /media/aleksejs/DataHDD/work/codes/image-analysis/behavioural/DeepLabCut_old/DeepLabCut/Generating_a_Training_Set/data-pia_shaved_running_1_test/CollectedData_Pia.csv\n",
      "Results will be saved in /media/aleksejs/DataHDD/work/codes/image-analysis/behavioural\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "  \"NODE_NAMES\"       : [\"ShoulderBlade\", \"Shoulder\", \"Wrist\", \"Finger\", \"Tip\"],\n",
    "  \"EDGE_NODES\"       : [[0,1], [1,2], [2,3], [3,4]],\n",
    "  \"NODE_MAX_V\"       : [70, 70, 70, 70, 70],\n",
    "  \"EDGE_MIN_R\"       : [0.5, 0.5, 0.5, 0.5],\n",
    "  \"EDGE_MAX_R\"       : [2, 2, 2, 2],\n",
    "  \"LIKELIHOOD_THR\"   : 0.05,\n",
    "  \"STICKMAN_CROP_X\"  : None,\n",
    "  \"STICKMAN_CROP_Y\"  : None\n",
    "}\n",
    "\n",
    "param[\"CONF_FNAME\"] = gui_fname(\"Select config file...\", \"./\", \"Config Files (*.yaml)\")\n",
    "param[\"AVI_FNAME\"] = gui_fname(\"Select original video file...\", \"./\", \"Video Files (*.avi)\")\n",
    "param[\"CSV_FNAME\"] = gui_fname(\"Select tracking file...\", \"./\", \"CSV Files (*.csv)\")\n",
    "param[\"REZ_FPATH\"] = gui_fpath(\"Select result path\", \"./\")\n",
    "\n",
    "print(\"Using config file\", param[\"CONF_FNAME\"])\n",
    "print(\"Using original video\", param[\"AVI_FNAME\"])\n",
    "print(\"Using tracking file\", param[\"CSV_FNAME\"])\n",
    "print(\"Results will be saved in\", param[\"REZ_FPATH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse data, compute and plot results\n",
    "\n",
    "Determine frames, that\n",
    "* Have low confidence based on DLC self-reported analysis\n",
    "* Do not fulfill node constraints (e.g. excessive velocity)\n",
    "* Do not fulfill edge constraints (e.g. too large or too small edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# Parse CSV file\n",
    "#########################\n",
    "\n",
    "X, Y, P = parse_dlc_csv(fname, param):\n",
    "nFrames, nNodes = X.shape\n",
    "    \n",
    "#########################\n",
    "# Compute Constraints\n",
    "#########################\n",
    "nodeLowConf, perr = likelihood_constrain(P, param)\n",
    "V, VLowConf, nodeBadV = velocity_constrain(X, Y, nodeLowConf, param)\n",
    "edgeLength, edgeLowConf, edgeBadLength = edge_constrain(X, Y, nodeLowConf, param)\n",
    "\n",
    "framesLowConf    = np.sum(nodeLowConf, axis=1) > 0\n",
    "framesBadV       = np.hstack(([0], np.sum(nodeBadV, axis=1) > 0))\n",
    "framesBadEdgeLen = np.sum(edgeBadLength, axis=1) > 0\n",
    "framesBadTotal   = np.logical_or(framesLowConf, framesBadV, framesBadEdgeLen)\n",
    "\n",
    "print(\"Average lengths of edges are\", edgeLenAvg)\n",
    "print(\"Total number of unconfident frames\", np.sum(framesLowConf > 0))\n",
    "print(\"Total number of frames with bad velocity\", np.sum(framesBadV))\n",
    "print(\"Total number of frames with bad edges\", np.sum(framesBadEdgeLen))\n",
    "print(\"Total number of frames bad in any way\", np.sum(framesBadTotal))\n",
    "\n",
    "#########################\n",
    "# Plot Statistics\n",
    "#########################\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "plotPerrCDF(ax[0][0], perr, param)                            # Plot CDF of node confidence\n",
    "plotVelocityCDF(ax[1][0], V, VLowConf, param)                 # Plot CDF of node velocities\n",
    "plotRelEdgeLenDistr(ax[0][1], edgeLength, edgeLowConf, param) # Plot relative edge length distributions\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create stickman video and write it to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# Make Stickman Video\n",
    "#########################\n",
    "\n",
    "# Use velocity as node constraint for stickman plot.\n",
    "# There is 1 less velocities than frames - fill with zeros, as we can't estimate velocity for the first frame\n",
    "nodeLowConstr = np.vstack((np.zeros(nNodes), nodeBadV))\n",
    "\n",
    "# Use edge length as edge constraint for stickman plot\n",
    "edgeLowConstr = np.copy(edgeBadLength)\n",
    "\n",
    "# Write stickman video\n",
    "stickman(X, Y, param, nodeLowConf, nodeLowConstr, edgeLowConf, edgeLowConstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training-Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide which frames will be selected for manual marking\n",
    "\n",
    "1. Check which constraints are present\n",
    "2. Merge constraints to decide which frames are bad, possibly rank them\n",
    "3. Extract numbers of frames that are bad\n",
    "4. Subsample fixed amount randomly, possibly rank-biased\n",
    "5. Extract actual frames, save as images \n",
    "\n",
    "**TODO**:\n",
    "* Rank-based selection\n",
    "* Clustering-based selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frameIdxs = np.linspace(1, nFrames, nFrames).astype(int)\n",
    "frameIdxsBad = frameIdxs[framesBadTotal]\n",
    "nBadFrames = len(frameIdxsBad)\n",
    "\n",
    "# Option 1: Select all bad frames\n",
    "# selectedFrames = frameIdxsBad\n",
    "\n",
    "# Option 2: Select fixed amount of bad frames uniformly\n",
    "selectedFrames = frameIdxsBad[selectUniform(nBadFrames, 40)]\n",
    "\n",
    "print(\"Selected frames are\", selectedFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract actual frames from the video, save them to the tracking folder\n",
    "\n",
    "**TODO**:\n",
    "* Inspect DLC outlier selection, perhaps can reuse functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file, [param[\"AVI_FNAME\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking-Only\n",
    "### Post-tracking marking\n",
    "\n",
    "**TODO**\n",
    "1. Run DLC_GUI on all selected frames\n",
    "2. Open resulting file, merge markings with current markings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing\n",
    "\n",
    "1. Mark all unconfident or unconstrained data as NAN\n",
    "2. Save data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set all bad coordinates to NAN\n",
    "X[framesBadTotal, :] = np.nan\n",
    "Y[framesBadTotal, :] = np.nan\n",
    "\n",
    "rez_fname_h5 = os.path.join(param[\"REZ_FPATH\"], \"result.h5\")\n",
    "print(\"Writing tracking data to\", rez_fname_h5)\n",
    "rezfile = h5py.File(rez_fname_h5, \"w\")\n",
    "rezfile['NODE_NAMES'] = param['NODE_NAMES']\n",
    "rezfile['X'] = X\n",
    "rezfile['Y'] = Y\n",
    "rezfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
